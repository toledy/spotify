{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liutianhan/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.linear_model import LassoCV,RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 200)\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read In Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, our goal is to generate processed training and test sets. First, we read in our data from csv file. We split the data into training and test, impute missing values through the mean and finally we transform response variables using log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read-in the full data set\n",
    "data = pd.read_csv('Final_Dataframe.csv')\n",
    "data = data.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>acousticness_mean</th>\n",
       "      <th>acousticness_std</th>\n",
       "      <th>dance_mean</th>\n",
       "      <th>dance_std</th>\n",
       "      <th>energy_mean</th>\n",
       "      <th>energy_std</th>\n",
       "      <th>instrumentalness_mean</th>\n",
       "      <th>instrumentalness_std</th>\n",
       "      <th>key_mean</th>\n",
       "      <th>key_std</th>\n",
       "      <th>liveness_mean</th>\n",
       "      <th>liveness_std</th>\n",
       "      <th>loudness_mean</th>\n",
       "      <th>loudness_std</th>\n",
       "      <th>mode_mean</th>\n",
       "      <th>mode_std</th>\n",
       "      <th>speech_mean</th>\n",
       "      <th>speech_std</th>\n",
       "      <th>tempo_mean</th>\n",
       "      <th>tempo_std</th>\n",
       "      <th>time_mean</th>\n",
       "      <th>time_std</th>\n",
       "      <th>valence_mean</th>\n",
       "      <th>valence_std</th>\n",
       "      <th>Followers</th>\n",
       "      <th>followers_mean</th>\n",
       "      <th>followers_std</th>\n",
       "      <th>popularity_mean</th>\n",
       "      <th>popularity_std</th>\n",
       "      <th>top_0_10</th>\n",
       "      <th>top_10_20</th>\n",
       "      <th>top_20_30</th>\n",
       "      <th>top_30_40</th>\n",
       "      <th>top_40_50</th>\n",
       "      <th>'acid house'</th>\n",
       "      <th>'album rock'</th>\n",
       "      <th>'alternative country'</th>\n",
       "      <th>'alternative dance'</th>\n",
       "      <th>'alternative metal'</th>\n",
       "      <th>'alternative pop'</th>\n",
       "      <th>'alternative rock'</th>\n",
       "      <th>'alternative roots rock'</th>\n",
       "      <th>'ambient'</th>\n",
       "      <th>'anthem emo'</th>\n",
       "      <th>'anthem worship'</th>\n",
       "      <th>'anti-folk'</th>\n",
       "      <th>'art rock'</th>\n",
       "      <th>'athens indie'</th>\n",
       "      <th>'austindie'</th>\n",
       "      <th>'australian alternative rock'</th>\n",
       "      <th>'australian dance'</th>\n",
       "      <th>'australian hip hop'</th>\n",
       "      <th>'australian pop'</th>\n",
       "      <th>'avant-garde'</th>\n",
       "      <th>'azonto'</th>\n",
       "      <th>'azontobeats'</th>\n",
       "      <th>'bass music'</th>\n",
       "      <th>'bay area indie'</th>\n",
       "      <th>'bebop'</th>\n",
       "      <th>'big band'</th>\n",
       "      <th>'big beat'</th>\n",
       "      <th>'big room'</th>\n",
       "      <th>'bluegrass'</th>\n",
       "      <th>'blues'</th>\n",
       "      <th>'blues-rock'</th>\n",
       "      <th>'boogie-woogie'</th>\n",
       "      <th>'bossa nova'</th>\n",
       "      <th>'boston rock'</th>\n",
       "      <th>'bow pop'</th>\n",
       "      <th>'breakbeat'</th>\n",
       "      <th>'brill building pop'</th>\n",
       "      <th>'british alternative rock'</th>\n",
       "      <th>'british blues'</th>\n",
       "      <th>'british folk'</th>\n",
       "      <th>'british indie rock'</th>\n",
       "      <th>'british invasion'</th>\n",
       "      <th>'britpop'</th>\n",
       "      <th>'brooklyn indie'</th>\n",
       "      <th>'brostep'</th>\n",
       "      <th>'bubblegum pop'</th>\n",
       "      <th>'c86'</th>\n",
       "      <th>'cabaret'</th>\n",
       "      <th>'canadian indie'</th>\n",
       "      <th>'canadian metal'</th>\n",
       "      <th>'canadian pop'</th>\n",
       "      <th>'candy pop'</th>\n",
       "      <th>'canterbury scene'</th>\n",
       "      <th>'catstep'</th>\n",
       "      <th>'ccm'</th>\n",
       "      <th>'cello'</th>\n",
       "      <th>'celtic rock'</th>\n",
       "      <th>'chamber pop'</th>\n",
       "      <th>'chamber psych'</th>\n",
       "      <th>'chaotic hardcore'</th>\n",
       "      <th>'chicago blues'</th>\n",
       "      <th>'chicago house'</th>\n",
       "      <th>'chicago indie'</th>\n",
       "      <th>'chicago soul'</th>\n",
       "      <th>'chillhop'</th>\n",
       "      <th>...</th>\n",
       "      <th>'nu age'</th>\n",
       "      <th>'nu metal'</th>\n",
       "      <th>'permanent wave'</th>\n",
       "      <th>'pixie'</th>\n",
       "      <th>'polka'</th>\n",
       "      <th>'pop emo'</th>\n",
       "      <th>'pop rap'</th>\n",
       "      <th>'pop rock'</th>\n",
       "      <th>'pop'</th>\n",
       "      <th>'post-screamo'</th>\n",
       "      <th>'post-teen pop'</th>\n",
       "      <th>'progressive deathcore'</th>\n",
       "      <th>'progressive post-hardcore'</th>\n",
       "      <th>'psychedelic doom'</th>\n",
       "      <th>'punk'</th>\n",
       "      <th>'quebecois'</th>\n",
       "      <th>'rap'</th>\n",
       "      <th>'redneck'</th>\n",
       "      <th>'reggae fusion'</th>\n",
       "      <th>'reggae'</th>\n",
       "      <th>'reggaeton'</th>\n",
       "      <th>'relaxative'</th>\n",
       "      <th>'scorecore'</th>\n",
       "      <th>'sheffield indie'</th>\n",
       "      <th>'shimmer pop'</th>\n",
       "      <th>'shiver pop'</th>\n",
       "      <th>'singer-songwriter'</th>\n",
       "      <th>'skate punk'</th>\n",
       "      <th>'slow core'</th>\n",
       "      <th>'slow game'</th>\n",
       "      <th>'spanish pop'</th>\n",
       "      <th>'speed garage'</th>\n",
       "      <th>'talent show'</th>\n",
       "      <th>'traditional country'</th>\n",
       "      <th>'trap latino'</th>\n",
       "      <th>'trap music'</th>\n",
       "      <th>'trip hop'</th>\n",
       "      <th>'tropical house'</th>\n",
       "      <th>'uk drill'</th>\n",
       "      <th>'uk hip hop'</th>\n",
       "      <th>'underground hip hop'</th>\n",
       "      <th>'vancouver indie'</th>\n",
       "      <th>'vapor soul'</th>\n",
       "      <th>'vegas indie'</th>\n",
       "      <th>'violin'</th>\n",
       "      <th>'viral pop'</th>\n",
       "      <th>'west coast trap'</th>\n",
       "      <th>'wrestling'</th>\n",
       "      <th>'no_genre'</th>\n",
       "      <th>Lil Wayne</th>\n",
       "      <th>Van Morrison</th>\n",
       "      <th>Galantis</th>\n",
       "      <th>Wiz Khalifa</th>\n",
       "      <th>Rihanna</th>\n",
       "      <th>Post Malone</th>\n",
       "      <th>Axwell /\\ Ingrosso</th>\n",
       "      <th>Young Thug</th>\n",
       "      <th>JAY Z</th>\n",
       "      <th>A$AP Rocky</th>\n",
       "      <th>Yo Gotti</th>\n",
       "      <th>Chance The Rapper</th>\n",
       "      <th>Led Zeppelin</th>\n",
       "      <th>Otis Redding</th>\n",
       "      <th>21 Savage</th>\n",
       "      <th>Deorro</th>\n",
       "      <th>Elton John</th>\n",
       "      <th>SZA</th>\n",
       "      <th>Ty Dolla $ign</th>\n",
       "      <th>Ryan Adams</th>\n",
       "      <th>Birdy</th>\n",
       "      <th>Miguel</th>\n",
       "      <th>Niall Horan</th>\n",
       "      <th>Ellie Goulding</th>\n",
       "      <th>Commodores</th>\n",
       "      <th>Radiohead</th>\n",
       "      <th>SYML</th>\n",
       "      <th>First Aid Kit</th>\n",
       "      <th>Lord Huron</th>\n",
       "      <th>Str_Best</th>\n",
       "      <th>Str_Workout</th>\n",
       "      <th>Str_Party</th>\n",
       "      <th>Str_Chill</th>\n",
       "      <th>Str_Acoustic</th>\n",
       "      <th>Str_2000s</th>\n",
       "      <th>Str_1990s</th>\n",
       "      <th>Str_1980s</th>\n",
       "      <th>Str_1970s</th>\n",
       "      <th>Str_1960s</th>\n",
       "      <th>house_acousticness_mean</th>\n",
       "      <th>hip hop_acousticness_std</th>\n",
       "      <th>pop_liveness_std</th>\n",
       "      <th>dance_liveness_std</th>\n",
       "      <th>r&amp;b_acousticness_std</th>\n",
       "      <th>rap_energy_std</th>\n",
       "      <th>rap_key_std</th>\n",
       "      <th>acoustic_acousticness_std</th>\n",
       "      <th>acoustic_acousticness_mean</th>\n",
       "      <th>acoustic_energy_std</th>\n",
       "      <th>acoustic_key_std</th>\n",
       "      <th>soul_acousticness_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.641282</td>\n",
       "      <td>3.058644</td>\n",
       "      <td>0.467911</td>\n",
       "      <td>4.148403</td>\n",
       "      <td>0.275940</td>\n",
       "      <td>4.428289</td>\n",
       "      <td>0.119650</td>\n",
       "      <td>3.608691</td>\n",
       "      <td>0.275940</td>\n",
       "      <td>4.428289</td>\n",
       "      <td>0.199440</td>\n",
       "      <td>6.131128</td>\n",
       "      <td>-18.000646</td>\n",
       "      <td>0.111308</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>2.056123</td>\n",
       "      <td>0.383051</td>\n",
       "      <td>2.479147</td>\n",
       "      <td>101.045969</td>\n",
       "      <td>0.019284</td>\n",
       "      <td>3.338462</td>\n",
       "      <td>0.643502</td>\n",
       "      <td>0.319263</td>\n",
       "      <td>4.061163</td>\n",
       "      <td>24.0</td>\n",
       "      <td>366.624695</td>\n",
       "      <td>2.736285e-06</td>\n",
       "      <td>42.833333</td>\n",
       "      <td>0.051084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.058644</td>\n",
       "      <td>6.131128</td>\n",
       "      <td>6.131128</td>\n",
       "      <td>3.058644</td>\n",
       "      <td>4.428289</td>\n",
       "      <td>4.428289</td>\n",
       "      <td>3.058644</td>\n",
       "      <td>0.641282</td>\n",
       "      <td>4.428289</td>\n",
       "      <td>4.428289</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.278816</td>\n",
       "      <td>3.805912</td>\n",
       "      <td>0.634392</td>\n",
       "      <td>7.129091</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>5.991548</td>\n",
       "      <td>0.192559</td>\n",
       "      <td>2.928603</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>5.991548</td>\n",
       "      <td>0.164490</td>\n",
       "      <td>7.768494</td>\n",
       "      <td>-9.525804</td>\n",
       "      <td>0.280768</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>1.980676</td>\n",
       "      <td>0.082210</td>\n",
       "      <td>7.627447</td>\n",
       "      <td>122.768255</td>\n",
       "      <td>0.035441</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.656235</td>\n",
       "      <td>4.076658</td>\n",
       "      <td>330.0</td>\n",
       "      <td>321.435189</td>\n",
       "      <td>3.011912e-06</td>\n",
       "      <td>48.903226</td>\n",
       "      <td>0.066535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278816</td>\n",
       "      <td>3.805912</td>\n",
       "      <td>7.768494</td>\n",
       "      <td>7.768494</td>\n",
       "      <td>3.805912</td>\n",
       "      <td>5.991548</td>\n",
       "      <td>5.991548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.805912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.228810</td>\n",
       "      <td>3.977396</td>\n",
       "      <td>0.600400</td>\n",
       "      <td>5.592818</td>\n",
       "      <td>0.612200</td>\n",
       "      <td>5.196620</td>\n",
       "      <td>0.179571</td>\n",
       "      <td>2.970854</td>\n",
       "      <td>0.612200</td>\n",
       "      <td>5.196620</td>\n",
       "      <td>0.192563</td>\n",
       "      <td>7.704437</td>\n",
       "      <td>-7.845333</td>\n",
       "      <td>0.307409</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.085665</td>\n",
       "      <td>0.052150</td>\n",
       "      <td>38.557531</td>\n",
       "      <td>114.439167</td>\n",
       "      <td>0.045459</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.807886</td>\n",
       "      <td>0.481787</td>\n",
       "      <td>3.980915</td>\n",
       "      <td>73.0</td>\n",
       "      <td>752.870879</td>\n",
       "      <td>7.006194e-07</td>\n",
       "      <td>60.280000</td>\n",
       "      <td>0.064466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.704437</td>\n",
       "      <td>7.704437</td>\n",
       "      <td>3.977396</td>\n",
       "      <td>5.196620</td>\n",
       "      <td>5.196620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.977396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.394114</td>\n",
       "      <td>2.758064</td>\n",
       "      <td>0.599424</td>\n",
       "      <td>6.611299</td>\n",
       "      <td>0.541097</td>\n",
       "      <td>3.451792</td>\n",
       "      <td>0.203059</td>\n",
       "      <td>3.008687</td>\n",
       "      <td>0.541097</td>\n",
       "      <td>3.451792</td>\n",
       "      <td>0.211488</td>\n",
       "      <td>5.238347</td>\n",
       "      <td>-9.764303</td>\n",
       "      <td>0.181115</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>2.015326</td>\n",
       "      <td>0.106724</td>\n",
       "      <td>8.893022</td>\n",
       "      <td>110.134788</td>\n",
       "      <td>0.039801</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0.511997</td>\n",
       "      <td>4.112335</td>\n",
       "      <td>6173.0</td>\n",
       "      <td>447.025150</td>\n",
       "      <td>3.385402e-06</td>\n",
       "      <td>58.696970</td>\n",
       "      <td>0.063990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394114</td>\n",
       "      <td>2.758064</td>\n",
       "      <td>5.238347</td>\n",
       "      <td>5.238347</td>\n",
       "      <td>2.758064</td>\n",
       "      <td>3.451792</td>\n",
       "      <td>3.451792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.194509</td>\n",
       "      <td>3.591057</td>\n",
       "      <td>0.531067</td>\n",
       "      <td>6.666606</td>\n",
       "      <td>0.759400</td>\n",
       "      <td>4.003118</td>\n",
       "      <td>0.115499</td>\n",
       "      <td>3.875675</td>\n",
       "      <td>0.759400</td>\n",
       "      <td>4.003118</td>\n",
       "      <td>0.234787</td>\n",
       "      <td>6.989281</td>\n",
       "      <td>-6.465367</td>\n",
       "      <td>0.246666</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.085665</td>\n",
       "      <td>0.129720</td>\n",
       "      <td>4.482143</td>\n",
       "      <td>124.789500</td>\n",
       "      <td>0.037045</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>3.941537</td>\n",
       "      <td>0.443407</td>\n",
       "      <td>3.941298</td>\n",
       "      <td>145.0</td>\n",
       "      <td>472.497380</td>\n",
       "      <td>2.033166e-06</td>\n",
       "      <td>49.516129</td>\n",
       "      <td>0.051309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.194509</td>\n",
       "      <td>3.591057</td>\n",
       "      <td>6.989281</td>\n",
       "      <td>6.989281</td>\n",
       "      <td>3.591057</td>\n",
       "      <td>4.003118</td>\n",
       "      <td>4.003118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.591057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 950 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  acousticness_mean  acousticness_std  dance_mean  dance_std  \\\n",
       "0           0           0.641282          3.058644    0.467911   4.148403   \n",
       "1           1           0.278816          3.805912    0.634392   7.129091   \n",
       "2           2           0.228810          3.977396    0.600400   5.592818   \n",
       "3           3           0.394114          2.758064    0.599424   6.611299   \n",
       "4           4           0.194509          3.591057    0.531067   6.666606   \n",
       "\n",
       "   energy_mean  energy_std  instrumentalness_mean  instrumentalness_std  \\\n",
       "0     0.275940    4.428289               0.119650              3.608691   \n",
       "1     0.596000    5.991548               0.192559              2.928603   \n",
       "2     0.612200    5.196620               0.179571              2.970854   \n",
       "3     0.541097    3.451792               0.203059              3.008687   \n",
       "4     0.759400    4.003118               0.115499              3.875675   \n",
       "\n",
       "   key_mean   key_std  liveness_mean  liveness_std  loudness_mean  \\\n",
       "0  0.275940  4.428289       0.199440      6.131128     -18.000646   \n",
       "1  0.596000  5.991548       0.164490      7.768494      -9.525804   \n",
       "2  0.612200  5.196620       0.192563      7.704437      -7.845333   \n",
       "3  0.541097  3.451792       0.211488      5.238347      -9.764303   \n",
       "4  0.759400  4.003118       0.234787      6.989281      -6.465367   \n",
       "\n",
       "   loudness_std  mode_mean  mode_std  speech_mean  speech_std  tempo_mean  \\\n",
       "0      0.111308   0.630769  2.056123     0.383051    2.479147  101.045969   \n",
       "1      0.280768   0.509804  1.980676     0.082210    7.627447  122.768255   \n",
       "2      0.307409   0.666667  2.085665     0.052150   38.557531  114.439167   \n",
       "3      0.181115   0.606061  2.015326     0.106724    8.893022  110.134788   \n",
       "4      0.246666   0.666667  2.085665     0.129720    4.482143  124.789500   \n",
       "\n",
       "   tempo_std  time_mean  time_std  valence_mean  valence_std  Followers  \\\n",
       "0   0.019284   3.338462  0.643502      0.319263     4.061163       24.0   \n",
       "1   0.035441   4.000000  5.000000      0.656235     4.076658      330.0   \n",
       "2   0.045459   4.000000  3.807886      0.481787     3.980915       73.0   \n",
       "3   0.039801   4.000000  2.828427      0.511997     4.112335     6173.0   \n",
       "4   0.037045   3.933333  3.941537      0.443407     3.941298      145.0   \n",
       "\n",
       "   followers_mean  followers_std  popularity_mean  popularity_std  top_0_10  \\\n",
       "0      366.624695   2.736285e-06        42.833333        0.051084         0   \n",
       "1      321.435189   3.011912e-06        48.903226        0.066535         0   \n",
       "2      752.870879   7.006194e-07        60.280000        0.064466         0   \n",
       "3      447.025150   3.385402e-06        58.696970        0.063990         0   \n",
       "4      472.497380   2.033166e-06        49.516129        0.051309         0   \n",
       "\n",
       "   top_10_20  top_20_30  top_30_40  top_40_50   'acid house'   'album rock'  \\\n",
       "0          0          0          0          0              0              0   \n",
       "1          0          0          0          0              0              0   \n",
       "2          0          0          1          0              0              0   \n",
       "3          0          0          0          0              0              1   \n",
       "4          0          0          0          0              0              0   \n",
       "\n",
       "    'alternative country'   'alternative dance'   'alternative metal'  \\\n",
       "0                       1                     0                     0   \n",
       "1                       0                     0                     0   \n",
       "2                       0                     1                     0   \n",
       "3                       0                     0                     0   \n",
       "4                       0                     0                     0   \n",
       "\n",
       "    'alternative pop'   'alternative rock'   'alternative roots rock'  \\\n",
       "0                   0                    1                          0   \n",
       "1                   0                    0                          0   \n",
       "2                   0                    0                          0   \n",
       "3                   0                    0                          0   \n",
       "4                   0                    1                          0   \n",
       "\n",
       "    'ambient'   'anthem emo'   'anthem worship'   'anti-folk'   'art rock'  \\\n",
       "0           0              1                  0             1            0   \n",
       "1           0              0                  0             1            0   \n",
       "2           0              0                  0             1            1   \n",
       "3           0              0                  0             0            1   \n",
       "4           0              0                  0             0            0   \n",
       "\n",
       "    'athens indie'   'austindie'   'australian alternative rock'  \\\n",
       "0                0             0                               0   \n",
       "1                0             0                               0   \n",
       "2                0             0                               0   \n",
       "3                0             0                               0   \n",
       "4                0             0                               0   \n",
       "\n",
       "    'australian dance'   'australian hip hop'   'australian pop'  \\\n",
       "0                    0                      0                  0   \n",
       "1                    0                      0                  0   \n",
       "2                    0                      0                  0   \n",
       "3                    0                      0                  0   \n",
       "4                    0                      0                  0   \n",
       "\n",
       "    'avant-garde'   'azonto'   'azontobeats'   'bass music'  \\\n",
       "0               0          0               0              0   \n",
       "1               0          0               0              0   \n",
       "2               0          0               0              0   \n",
       "3               0          0               0              0   \n",
       "4               0          0               0              0   \n",
       "\n",
       "    'bay area indie'   'bebop'   'big band'   'big beat'   'big room'  \\\n",
       "0                  0         0            0            0            0   \n",
       "1                  0         0            0            0            1   \n",
       "2                  0         0            0            1            0   \n",
       "3                  0         0            0            0            0   \n",
       "4                  0         1            0            0            0   \n",
       "\n",
       "    'bluegrass'   'blues'   'blues-rock'   'boogie-woogie'   'bossa nova'  \\\n",
       "0             0         0              0                 0              0   \n",
       "1             0         0              1                 0              0   \n",
       "2             0         0              0                 0              0   \n",
       "3             0         0              1                 0              0   \n",
       "4             0         0              0                 0              0   \n",
       "\n",
       "    'boston rock'   'bow pop'   'breakbeat'   'brill building pop'  \\\n",
       "0               0           0             0                      0   \n",
       "1               0           0             0                      0   \n",
       "2               0           0             1                      0   \n",
       "3               0           0             0                      1   \n",
       "4               0           0             0                      0   \n",
       "\n",
       "    'british alternative rock'   'british blues'   'british folk'  \\\n",
       "0                            0                 0                1   \n",
       "1                            0                 0                0   \n",
       "2                            0                 0                0   \n",
       "3                            0                 1                0   \n",
       "4                            0                 0                0   \n",
       "\n",
       "    'british indie rock'   'british invasion'   'britpop'   'brooklyn indie'  \\\n",
       "0                      0                    0           0                  0   \n",
       "1                      0                    1           0                  0   \n",
       "2                      0                    0           0                  0   \n",
       "3                      0                    0           0                  0   \n",
       "4                      0                    0           1                  0   \n",
       "\n",
       "    'brostep'   'bubblegum pop'   'c86'   'cabaret'   'canadian indie'  \\\n",
       "0           0                 0       0           0                  0   \n",
       "1           1                 0       0           0                  0   \n",
       "2           0                 0       0           0                  0   \n",
       "3           0                 1       0           0                  0   \n",
       "4           0                 0       1           0                  1   \n",
       "\n",
       "    'canadian metal'   'canadian pop'   'candy pop'   'canterbury scene'  \\\n",
       "0                  0                0             0                    0   \n",
       "1                  0                0             0                    0   \n",
       "2                  0                0             0                    0   \n",
       "3                  0                0             0                    0   \n",
       "4                  0                1             0                    0   \n",
       "\n",
       "    'catstep'   'ccm'   'cello'   'celtic rock'   'chamber pop'  \\\n",
       "0           0       0         0               0               1   \n",
       "1           1       0         0               0               0   \n",
       "2           0       0         0               0               1   \n",
       "3           0       0         0               0               0   \n",
       "4           0       0         0               0               1   \n",
       "\n",
       "    'chamber psych'   'chaotic hardcore'   'chicago blues'   'chicago house'  \\\n",
       "0                 1                    0                 0                 0   \n",
       "1                 0                    0                 0                 0   \n",
       "2                 0                    0                 0                 0   \n",
       "3                 0                    1                 0                 0   \n",
       "4                 0                    0                 0                 0   \n",
       "\n",
       "    'chicago indie'   'chicago soul'   'chillhop'          ...            \\\n",
       "0                 0                0            0          ...             \n",
       "1                 0                0            0          ...             \n",
       "2                 0                0            0          ...             \n",
       "3                 0                0            0          ...             \n",
       "4                 0                0            0          ...             \n",
       "\n",
       "   'nu age'  'nu metal'  'permanent wave'  'pixie'  'polka'  'pop emo'  \\\n",
       "0         0           0                 0        0        0          0   \n",
       "1         0           0                 0        0        0          0   \n",
       "2         0           0                 0        0        0          0   \n",
       "3         0           0                 0        0        0          0   \n",
       "4         0           0                 0        0        0          0   \n",
       "\n",
       "   'pop rap'  'pop rock'  'pop'  'post-screamo'  'post-teen pop'  \\\n",
       "0          0           0      0               0                0   \n",
       "1          0           0      0               0                0   \n",
       "2          0           0      0               0                0   \n",
       "3          1           0      0               0                0   \n",
       "4          1           0      0               0                0   \n",
       "\n",
       "   'progressive deathcore'  'progressive post-hardcore'  'psychedelic doom'  \\\n",
       "0                        0                            0                   0   \n",
       "1                        0                            0                   0   \n",
       "2                        0                            0                   0   \n",
       "3                        0                            0                   0   \n",
       "4                        0                            0                   0   \n",
       "\n",
       "   'punk'  'quebecois'  'rap'  'redneck'  'reggae fusion'  'reggae'  \\\n",
       "0       0            0      0          0                0         0   \n",
       "1       0            0      0          0                0         0   \n",
       "2       0            0      0          0                0         0   \n",
       "3       0            0      0          0                0         0   \n",
       "4       0            0      0          0                0         0   \n",
       "\n",
       "   'reggaeton'  'relaxative'  'scorecore'  'sheffield indie'  'shimmer pop'  \\\n",
       "0            0             0            0                  0              0   \n",
       "1            0             0            0                  0              0   \n",
       "2            0             0            0                  0              0   \n",
       "3            0             0            0                  0              0   \n",
       "4            0             0            0                  0              0   \n",
       "\n",
       "   'shiver pop'  'singer-songwriter'  'skate punk'  'slow core'  'slow game'  \\\n",
       "0             0                    0             0            0            0   \n",
       "1             0                    0             0            0            0   \n",
       "2             0                    0             0            0            0   \n",
       "3             0                    0             0            0            0   \n",
       "4             0                    0             0            0            0   \n",
       "\n",
       "   'spanish pop'  'speed garage'  'talent show'  'traditional country'  \\\n",
       "0              0               0              0                      0   \n",
       "1              0               0              0                      0   \n",
       "2              0               0              0                      0   \n",
       "3              0               0              0                      0   \n",
       "4              0               0              0                      0   \n",
       "\n",
       "   'trap latino'  'trap music'  'trip hop'  'tropical house'  'uk drill'  \\\n",
       "0              0             0           0                 0           0   \n",
       "1              0             0           0                 0           0   \n",
       "2              0             0           0                 0           0   \n",
       "3              0             0           0                 0           0   \n",
       "4              0             0           0                 0           0   \n",
       "\n",
       "   'uk hip hop'  'underground hip hop'  'vancouver indie'  'vapor soul'  \\\n",
       "0             0                      0                  0             0   \n",
       "1             0                      0                  0             0   \n",
       "2             0                      0                  0             0   \n",
       "3             0                      0                  0             0   \n",
       "4             0                      0                  0             1   \n",
       "\n",
       "   'vegas indie'  'violin'  'viral pop'  'west coast trap'  'wrestling'  \\\n",
       "0              0         0            0                  0            0   \n",
       "1              0         0            0                  0            0   \n",
       "2              0         0            0                  0            0   \n",
       "3              0         1            0                  0            0   \n",
       "4              0         0            0                  0            0   \n",
       "\n",
       "   'no_genre'  Lil Wayne  Van Morrison  Galantis  Wiz Khalifa  Rihanna  \\\n",
       "0           1          0             0         0            0        0   \n",
       "1           1          0             0         0            0        0   \n",
       "2           1          0             0         0            0        0   \n",
       "3           1          0             0         0            0        0   \n",
       "4           1          0             0         0            0        0   \n",
       "\n",
       "   Post Malone  Axwell /\\ Ingrosso  Young Thug  JAY Z  A$AP Rocky  Yo Gotti  \\\n",
       "0            0                   0           0      0           0         0   \n",
       "1            0                   0           0      0           0         0   \n",
       "2            0                   0           0      0           0         0   \n",
       "3            0                   0           0      0           0         0   \n",
       "4            0                   0           0      0           0         0   \n",
       "\n",
       "   Chance The Rapper  Led Zeppelin  Otis Redding  21 Savage  Deorro  \\\n",
       "0                  0             0             0          0       0   \n",
       "1                  0             0             0          0       0   \n",
       "2                  0             0             0          0       0   \n",
       "3                  0             0             0          0       0   \n",
       "4                  0             0             0          0       0   \n",
       "\n",
       "   Elton John  SZA  Ty Dolla $ign  Ryan Adams  Birdy  Miguel  Niall Horan  \\\n",
       "0           0    0              0           0      0       0            0   \n",
       "1           0    0              0           0      0       0            0   \n",
       "2           0    0              0           0      0       0            0   \n",
       "3           0    0              0           0      0       0            0   \n",
       "4           0    0              0           0      0       0            0   \n",
       "\n",
       "   Ellie Goulding  Commodores  Radiohead  SYML  First Aid Kit  Lord Huron  \\\n",
       "0               0           0          0     0              0           0   \n",
       "1               0           0          0     0              0           0   \n",
       "2               0           0          0     0              0           0   \n",
       "3               0           0          0     0              0           0   \n",
       "4               0           0          0     0              0           0   \n",
       "\n",
       "   Str_Best  Str_Workout  Str_Party  Str_Chill  Str_Acoustic  Str_2000s  \\\n",
       "0         0            0          0          0             0          0   \n",
       "1         0            0          0          0             0          0   \n",
       "2         0            0          0          0             0          0   \n",
       "3         0            0          0          0             0          0   \n",
       "4         0            0          0          0             0          0   \n",
       "\n",
       "   Str_1990s  Str_1980s  Str_1970s  Str_1960s  house_acousticness_mean  \\\n",
       "0          0          0          0          0                 0.000000   \n",
       "1          1          0          1          0                 0.278816   \n",
       "2          0          0          0          0                 0.228810   \n",
       "3          0          0          0          0                 0.394114   \n",
       "4          0          0          0          0                 0.194509   \n",
       "\n",
       "   hip hop_acousticness_std  pop_liveness_std  dance_liveness_std  \\\n",
       "0                  3.058644          6.131128            6.131128   \n",
       "1                  3.805912          7.768494            7.768494   \n",
       "2                  0.000000          7.704437            7.704437   \n",
       "3                  2.758064          5.238347            5.238347   \n",
       "4                  3.591057          6.989281            6.989281   \n",
       "\n",
       "   r&b_acousticness_std  rap_energy_std  rap_key_std  \\\n",
       "0              3.058644        4.428289     4.428289   \n",
       "1              3.805912        5.991548     5.991548   \n",
       "2              3.977396        5.196620     5.196620   \n",
       "3              2.758064        3.451792     3.451792   \n",
       "4              3.591057        4.003118     4.003118   \n",
       "\n",
       "   acoustic_acousticness_std  acoustic_acousticness_mean  acoustic_energy_std  \\\n",
       "0                   3.058644                    0.641282             4.428289   \n",
       "1                   0.000000                    0.000000             0.000000   \n",
       "2                   0.000000                    0.000000             0.000000   \n",
       "3                   0.000000                    0.000000             0.000000   \n",
       "4                   0.000000                    0.000000             0.000000   \n",
       "\n",
       "   acoustic_key_std  soul_acousticness_std  \n",
       "0          4.428289               0.000000  \n",
       "1          0.000000               3.805912  \n",
       "2          0.000000               3.977396  \n",
       "3          0.000000               0.000000  \n",
       "4          0.000000               3.591057  \n",
       "\n",
       "[5 rows x 950 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## train, test split##\n",
    "\n",
    "# A train/test split is constructed where 90% of the subsample is \n",
    "# the train data set and 10% the test data set.\n",
    "\n",
    "# Set train and test sizes\n",
    "train_size = 0.9\n",
    "test_size = 1-train_size\n",
    "\n",
    "# Function to return random train and test sets\n",
    "def data_splitter(df, train, validate=False, seed=9001):\n",
    "    \n",
    "    if validate:\n",
    "        np.random.seed(seed)\n",
    "        perm = np.random.permutation(df.index)\n",
    "        m = len(df)\n",
    "        train_end = int(train * m)\n",
    "        validate_end = int(validate * m) + train_end\n",
    "        train = df.ix[perm[:train_end]]\n",
    "        validate = df.ix[perm[train_end:validate_end]]\n",
    "        test = df.ix[perm[validate_end:]]\n",
    "        return train, validate, test\n",
    "    else:\n",
    "        np.random.seed(seed)\n",
    "        perm = np.random.permutation(df.index)\n",
    "        m = len(df)\n",
    "        train_end = int(train * m)\n",
    "        train = df.ix[perm[:train_end]]\n",
    "        test = df.ix[perm[train_end:]]\n",
    "        return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: (1278, 949)\n",
      "Test Size: (142, 949)\n"
     ]
    }
   ],
   "source": [
    "# Create train and test dataframes from subsample\n",
    "train_df, test_df = data_splitter(data, train_size)\n",
    "\n",
    "# Return shapes of train and test dataframes\n",
    "print(\"Train Size: {}\".format(train_df.shape))\n",
    "print(\"Test Size: {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Median imputation of missing values\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=1)\n",
    "train_df = pd.DataFrame(imp.fit_transform(train_df), columns=data.columns)\n",
    "test_df = pd.DataFrame(imp.transform(test_df), columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['Followers'] != 0]\n",
    "test_df = test_df[test_df['Followers'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final step: create y_train/x_train and y_test/x_test dataframes\n",
    "\n",
    "# Initialize the training data\n",
    "y_train = np.log(train_df['Followers'])\n",
    "x_train = train_df.drop('Followers', axis=1)\n",
    "\n",
    "# Initialize the testing data\n",
    "y_test = np.log(test_df['Followers'])\n",
    "x_test = test_df.drop('Followers', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, our goal is to examine the baseline performance of simple models on the test set. We would use these baseline test set r2 score as a reference for building more complex models. The models included in this section are mostly multilinear regression models with different subset of predictors and possible polynomial/interaction terms. PCA and LASSO/RRIDGE are explored here as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part(a) Multilinear regression model with all predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test r2 score for multilinear regression model with all predictors is -2.779. This is evidence suggesting that we might be overfitting our model with too many predictors. Therefore, going forward (part (e)), we would like to fit a regression model with only significant predictors in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For multilinear regression with all terms,R2 score for training set: 0.7655523815712503\n",
      "For multilinear regression with all terms,R2 score for test set: -2.779712758436489\n"
     ]
    }
   ],
   "source": [
    "X=sm.add_constant(x_train)\n",
    "X_test=sm.add_constant(x_test)\n",
    "model=sm.OLS(y_train,X)\n",
    "results=model.fit()\n",
    "r2_test_a=r2_score(y_test,results.predict(X_test))\n",
    "print(\"For multilinear regression with all terms,R2 score for training set: {}\".format(r2_score(y_train,results.predict(X))))\n",
    "print(\"For multilinear regression with all terms,R2 score for test set: {}\".format(r2_test_a))\n",
    "#results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part(b) Multilinear regression model with top artists predictors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our prelimnary EDA anlaysis, we believed that top artists would be a good predictor for the success of a playlist. Therefore, here we fit two models in part (b) and (c) that only include predictors including artists. In part (b), we use the presence of top 30 artists as predictors. As a note, for part (b), top artist are those who appear most often in playlists with 350,000+ followers. With more than 350,000 followers, a playlist will be in the top 20% in terms of followers. \n",
    "\n",
    "Our regression generates a test r2 score of 0.017, which is a lot better than -2.8 in part (a). Therefore, there is good reason to consider these predictors in future model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With tio 30 artists,R2 score for test set: 0.017373740567596885\n"
     ]
    }
   ],
   "source": [
    "top_30_artist_col=['Lil Wayne', 'Van Morrison', 'Galantis',\n",
    "       'Wiz Khalifa', 'Rihanna', 'Post Malone', 'Axwell /\\ Ingrosso',\n",
    "       'Young Thug', 'JAY Z', 'A$AP Rocky', 'Yo Gotti', 'Chance The Rapper',\n",
    "       'Led Zeppelin', 'Otis Redding', '21 Savage', 'Deorro', 'Elton John',\n",
    "       'SZA', 'Ty Dolla $ign', 'Ryan Adams', 'Birdy', 'Miguel', 'Niall Horan',\n",
    "       'Ellie Goulding', 'Commodores', 'Radiohead', 'SYML', 'First Aid Kit',\n",
    "       'Lord Huron']\n",
    "\n",
    "x_train_art=x_train[top_30_artist_col]\n",
    "x_test_art=x_test[top_30_artist_col]\n",
    "\n",
    "X1=sm.add_constant(x_train_art)\n",
    "X2=sm.add_constant(x_test_art)\n",
    "model2=sm.OLS(y_train,X1)\n",
    "results2=model2.fit()\n",
    "print(\"With top 30 artists,R2 score for test set: {}\".format(r2_score(y_test,results2.predict(X2))))\n",
    "#results2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['const', 'Galantis', 'Post Malone', 'Yo Gotti', 'Ellie Goulding'], dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#significant artistis\n",
    "results2.pvalues[results2.pvalues < 0.05].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  part(c) Multilinear regression model with top artists counts predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top artists are defined different for part (b) and part (c).Here, top artists are ranked by the total number of followers that playlists including this artist aggregate to. For part (c), the predictors are the number of top 10/10-20/20-30/30-40/40-50 artists that a playlist has.\n",
    "\n",
    "We see that r2 test result is -0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With only the significant terms from the last model,R2 score for test set: -0.031235636069632644\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Followers</td>    <th>  R-squared:         </th> <td>   0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2017</td> <th>  Prob (F-statistic):</th>  <td>0.00702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:19:12</td>     <th>  Log-Likelihood:    </th> <td> -3166.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1257</td>      <th>  AIC:               </th> <td>   6345.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1251</td>      <th>  BIC:               </th> <td>   6376.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td>    9.6438</td> <td>    0.097</td> <td>   99.900</td> <td> 0.000</td> <td>    9.454</td> <td>    9.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>top_0_10</th>  <td>    0.1075</td> <td>    0.274</td> <td>    0.392</td> <td> 0.695</td> <td>   -0.431</td> <td>    0.646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>top_10_20</th> <td>    0.2819</td> <td>    0.358</td> <td>    0.788</td> <td> 0.431</td> <td>   -0.420</td> <td>    0.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>top_20_30</th> <td>   -0.1965</td> <td>    0.280</td> <td>   -0.702</td> <td> 0.483</td> <td>   -0.745</td> <td>    0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>top_30_40</th> <td>    0.7624</td> <td>    0.273</td> <td>    2.789</td> <td> 0.005</td> <td>    0.226</td> <td>    1.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>top_40_50</th> <td>    0.7486</td> <td>    0.321</td> <td>    2.330</td> <td> 0.020</td> <td>    0.118</td> <td>    1.379</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>79.718</td> <th>  Durbin-Watson:     </th> <td>   1.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  83.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.595</td> <th>  Prob(JB):          </th> <td>6.73e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.574</td> <th>  Cond. No.          </th> <td>    4.32</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              Followers   R-squared:                       0.013\n",
       "Model:                            OLS   Adj. R-squared:                  0.009\n",
       "Method:                 Least Squares   F-statistic:                     3.204\n",
       "Date:                Tue, 05 Dec 2017   Prob (F-statistic):            0.00702\n",
       "Time:                        00:19:12   Log-Likelihood:                -3166.5\n",
       "No. Observations:                1257   AIC:                             6345.\n",
       "Df Residuals:                    1251   BIC:                             6376.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.6438      0.097     99.900      0.000       9.454       9.833\n",
       "top_0_10       0.1075      0.274      0.392      0.695      -0.431       0.646\n",
       "top_10_20      0.2819      0.358      0.788      0.431      -0.420       0.984\n",
       "top_20_30     -0.1965      0.280     -0.702      0.483      -0.745       0.352\n",
       "top_30_40      0.7624      0.273      2.789      0.005       0.226       1.299\n",
       "top_40_50      0.7486      0.321      2.330      0.020       0.118       1.379\n",
       "==============================================================================\n",
       "Omnibus:                       79.718   Durbin-Watson:                   1.945\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               83.686\n",
       "Skew:                          -0.595   Prob(JB):                     6.73e-19\n",
       "Kurtosis:                       2.574   Cond. No.                         4.32\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_art_count=x_train[top_artist_count_columns]\n",
    "x_test_art_count=x_test[top_artist_count_columns]\n",
    "\n",
    "X3=sm.add_constant(x_train_art_count)\n",
    "X4=sm.add_constant(x_test_art_count)\n",
    "model3=sm.OLS(y_train,X3)\n",
    "results3=model3.fit()\n",
    "print(\"With top artists count predictors,R2 score for test set: {}\".format(r2_score(y_test,results3.predict(X4))))\n",
    "results3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part(d) Multilinear regression model with genre predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our prelimnary EDA anlaysis, we also believed that genres would be a good predictor for playlist followers. Therefore, we fit a regression model with only genre predictors. Hereï¼Œeach predictors is a categorical variable indicating whether the playlist belongs to a specified genre.\n",
    "\n",
    "We see that test r2 score is -3.785. This could be the result of overfitting since we have 865 genre columns. A subset of genre predictors could still be important and will be considered for building future models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With only the significant terms from the last model,R2 score for test set: -3.7847086814421367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "865"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_genre=x_train[genre_columns]\n",
    "x_test_genre=x_test[genre_columns]\n",
    "\n",
    "X5=sm.add_constant(x_train_genre)\n",
    "X6=sm.add_constant(x_test_genre)\n",
    "model4=sm.OLS(y_train,X5)\n",
    "results4=model4.fit()\n",
    "print(\"With only the significant terms from the last model,R2 score for test set: {}\".format(r2_score(y_test,results4.predict(X6))))\n",
    "#results4.summary()\n",
    "len(genre_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (e) Multilinear regression with only siginifcant predictors from part (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part(e), we fit a model with siginificant predictors from model in part(a) to reduce overfitting. We have a total of 49 predictors (cut down from 949 originally).\n",
    "\n",
    "We see that test r2 score goes up to 0.085, which is the best r2 score so far. This indicates that our previous model indeed suffer from overfitting. We should workin on choosing a subset of original predictors as predictors for furture models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instrumentalness_mean', 'liveness_mean', 'loudness_std', 'speech_mean',\n",
       "       'time_std', 'valence_mean', ' 'bass music'', ' 'big band'',\n",
       "       ' 'christian punk'', ' 'country gospel'', ' 'crunk'', ' 'deep house'',\n",
       "       ' 'dubstep'', ' 'ectofolk'', ' 'electro house'', ' 'escape room'',\n",
       "       ' 'experimental'', ' 'filter house'', ' 'garage rock'', ' 'latin pop'',\n",
       "       ' 'modern blues'', ' 'modern country rock'', ' 'new orleans jazz'',\n",
       "       ' 'pop emo'', ' 'pop punk'', ' 'progressive electro house'',\n",
       "       ' 'progressive house'', ' 'progressive uplifting trance'',\n",
       "       ' 'traditional folk'', ' 'trip hop'', ''alternative rock'',\n",
       "       ''austindie'', ''blues-rock'', ''canadian metal'', ''chillhop'',\n",
       "       ''columbus ohio indie'', ''dance-punk'', ''deep new americana'',\n",
       "       ''edm'', ''g funk'', ''indie punk'', ''pop'',\n",
       "       ''progressive post-hardcore'', ''speed garage'', 'Radiohead',\n",
       "       'Str_Best', 'Str_Acoustic', 'Str_2000s', 'dance_liveness_std'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_preds=results.pvalues[results.pvalues < 0.05].index\n",
    "len(sig_preds)\n",
    "sig_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With only the significant terms from the last model,R2 score for test set: 0.0825894720034378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Followers</td>    <th>  R-squared:         </th> <td>   0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   7.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2017</td> <th>  Prob (F-statistic):</th> <td>1.25e-39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:54:47</td>     <th>  Log-Likelihood:    </th> <td> -3016.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1257</td>      <th>  AIC:               </th> <td>   6132.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1207</td>      <th>  BIC:               </th> <td>   6389.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    49</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                           <td>   15.2241</td> <td>    0.950</td> <td>   16.027</td> <td> 0.000</td> <td>   13.361</td> <td>   17.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>instrumentalness_mean</th>           <td>   -3.1447</td> <td>    1.089</td> <td>   -2.887</td> <td> 0.004</td> <td>   -5.282</td> <td>   -1.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>liveness_mean</th>                   <td>  -12.1780</td> <td>    2.358</td> <td>   -5.164</td> <td> 0.000</td> <td>  -16.804</td> <td>   -7.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loudness_std</th>                    <td>    3.3418</td> <td>    1.299</td> <td>    2.572</td> <td> 0.010</td> <td>    0.793</td> <td>    5.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>speech_mean</th>                     <td>   -2.5326</td> <td>    0.971</td> <td>   -2.608</td> <td> 0.009</td> <td>   -4.438</td> <td>   -0.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_std</th>                        <td> -1.25e-08</td> <td> 3.99e-09</td> <td>   -3.131</td> <td> 0.002</td> <td>-2.03e-08</td> <td>-4.67e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>valence_mean</th>                    <td>   -7.3241</td> <td>    1.413</td> <td>   -5.183</td> <td> 0.000</td> <td>  -10.096</td> <td>   -4.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'bass music'</th>                   <td>   -0.4514</td> <td>    0.405</td> <td>   -1.116</td> <td> 0.265</td> <td>   -1.245</td> <td>    0.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'big band'</th>                     <td>    0.2267</td> <td>    0.316</td> <td>    0.718</td> <td> 0.473</td> <td>   -0.393</td> <td>    0.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'christian punk'</th>               <td>   -1.1516</td> <td>    0.685</td> <td>   -1.682</td> <td> 0.093</td> <td>   -2.495</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'country gospel'</th>               <td>   -0.1673</td> <td>    0.326</td> <td>   -0.514</td> <td> 0.607</td> <td>   -0.806</td> <td>    0.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'crunk'</th>                        <td>    1.4932</td> <td>    0.785</td> <td>    1.901</td> <td> 0.058</td> <td>   -0.048</td> <td>    3.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'deep house'</th>                   <td>    0.3671</td> <td>    0.299</td> <td>    1.226</td> <td> 0.220</td> <td>   -0.220</td> <td>    0.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'dubstep'</th>                      <td>    0.6460</td> <td>    0.540</td> <td>    1.196</td> <td> 0.232</td> <td>   -0.414</td> <td>    1.706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'ectofolk'</th>                     <td>   -2.1576</td> <td>    1.148</td> <td>   -1.880</td> <td> 0.060</td> <td>   -4.409</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'electro house'</th>                <td>   -0.2006</td> <td>    0.233</td> <td>   -0.859</td> <td> 0.390</td> <td>   -0.659</td> <td>    0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'escape room'</th>                  <td>    0.6030</td> <td>    0.182</td> <td>    3.308</td> <td> 0.001</td> <td>    0.245</td> <td>    0.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'experimental'</th>                 <td>    0.1237</td> <td>    0.213</td> <td>    0.580</td> <td> 0.562</td> <td>   -0.295</td> <td>    0.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'filter house'</th>                 <td>    1.0122</td> <td>    0.338</td> <td>    2.993</td> <td> 0.003</td> <td>    0.349</td> <td>    1.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'garage rock'</th>                  <td>    0.2319</td> <td>    0.201</td> <td>    1.154</td> <td> 0.249</td> <td>   -0.163</td> <td>    0.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'latin pop'</th>                    <td>    0.4265</td> <td>    0.220</td> <td>    1.942</td> <td> 0.052</td> <td>   -0.004</td> <td>    0.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'modern blues'</th>                 <td>    0.5259</td> <td>    0.187</td> <td>    2.809</td> <td> 0.005</td> <td>    0.159</td> <td>    0.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'modern country rock'</th>          <td>    0.4418</td> <td>    0.190</td> <td>    2.321</td> <td> 0.020</td> <td>    0.068</td> <td>    0.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'new orleans jazz'</th>             <td>   -0.4096</td> <td>    0.363</td> <td>   -1.128</td> <td> 0.260</td> <td>   -1.122</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'pop emo'</th>                      <td>   -0.1501</td> <td>    0.209</td> <td>   -0.719</td> <td> 0.472</td> <td>   -0.560</td> <td>    0.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'pop punk'</th>                     <td>    0.4633</td> <td>    0.185</td> <td>    2.504</td> <td> 0.012</td> <td>    0.100</td> <td>    0.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'progressive electro house'</th>    <td>    0.5527</td> <td>    0.332</td> <td>    1.666</td> <td> 0.096</td> <td>   -0.098</td> <td>    1.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'progressive house'</th>            <td>   -0.3463</td> <td>    0.331</td> <td>   -1.048</td> <td> 0.295</td> <td>   -0.995</td> <td>    0.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'progressive uplifting trance'</th> <td>   -0.3538</td> <td>    0.817</td> <td>   -0.433</td> <td> 0.665</td> <td>   -1.957</td> <td>    1.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'traditional folk'</th>             <td>   -0.0593</td> <td>    0.365</td> <td>   -0.163</td> <td> 0.871</td> <td>   -0.776</td> <td>    0.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> 'trip hop'</th>                     <td>    0.9485</td> <td>    0.391</td> <td>    2.429</td> <td> 0.015</td> <td>    0.182</td> <td>    1.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>'alternative rock'</th>              <td>    0.1924</td> <td>    0.197</td> <td>    0.974</td> <td> 0.330</td> <td>   -0.195</td> <td>    0.580</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>'austindie'</th>                     <td>    0.6574</td> <td>    0.505</td> <td>    1.301</td> <td> 0.194</td> <td>   -0.334</td> <td>    1.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>'blues-rock'</th>                    <td>   -0.3016</td> <td>    0.243</td> <td>   -1.241</td> <td> 0.215</td> <td>   -0.778</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>'canadian metal'</th>                <td>    0.7083</td> <td>    0.857</td> <td>    0.827</td> <td> 0.409</td> <td>   -0.972</td> <td>    2.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>'chillhop'</th>                      <td>   -0.6586</td> <td>    0.847</td> <td>   -0.778</td> <td> 0.437</td> <td>   -2.320</td> <td>    1.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>'columbus ohio indie'</th>           <td>   -0.8179</td> <td>    0.535</td> <td>   -1.528</td> <td> 0.127</td> <td>   -1.868</td> <td>    0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>'dance-punk'</th>                    <td>   -0.3826</td> <td>    0.571</td> <td>   -0.670</td> <td> 0.503</td> <td>   -1.503</td> <td>    0.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>'deep new americana'</th>            <td>    0.0373</td> <td>    0.218</td> <td>    0.171</td> <td> 0.864</td> <td>   -0.391</td> <td>    0.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>'edm'</th>                           <td>    0.6196</td> <td>    0.301</td> <td>    2.062</td> <td> 0.039</td> <td>    0.030</td> <td>    1.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>'g funk'</th>                        <td>   -0.5112</td> <td>    0.420</td> <td>   -1.217</td> <td> 0.224</td> <td>   -1.335</td> <td>    0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>'indie punk'</th>                    <td>    0.0738</td> <td>    0.430</td> <td>    0.172</td> <td> 0.864</td> <td>   -0.769</td> <td>    0.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>'pop'</th>                           <td>    0.5996</td> <td>    0.276</td> <td>    2.175</td> <td> 0.030</td> <td>    0.059</td> <td>    1.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>'progressive post-hardcore'</th>     <td>    0.7197</td> <td>    0.449</td> <td>    1.603</td> <td> 0.109</td> <td>   -0.161</td> <td>    1.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>'speed garage'</th>                  <td>   -0.3341</td> <td>    0.646</td> <td>   -0.517</td> <td> 0.605</td> <td>   -1.602</td> <td>    0.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radiohead</th>                       <td>   -0.8771</td> <td>    0.821</td> <td>   -1.068</td> <td> 0.286</td> <td>   -2.489</td> <td>    0.735</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Str_Best</th>                        <td>   -1.2647</td> <td>    0.330</td> <td>   -3.837</td> <td> 0.000</td> <td>   -1.911</td> <td>   -0.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Str_Acoustic</th>                    <td>    3.1248</td> <td>    0.617</td> <td>    5.064</td> <td> 0.000</td> <td>    1.914</td> <td>    4.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Str_2000s</th>                       <td>   -3.0511</td> <td>    0.381</td> <td>   -8.006</td> <td> 0.000</td> <td>   -3.799</td> <td>   -2.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dance_liveness_std</th>              <td>   -0.1096</td> <td>    0.030</td> <td>   -3.650</td> <td> 0.000</td> <td>   -0.169</td> <td>   -0.051</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>31.737</td> <th>  Durbin-Watson:     </th> <td>   1.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  33.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.395</td> <th>  Prob(JB):          </th> <td>4.87e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.868</td> <th>  Cond. No.          </th> <td>6.39e+08</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              Followers   R-squared:                       0.223\n",
       "Model:                            OLS   Adj. R-squared:                  0.191\n",
       "Method:                 Least Squares   F-statistic:                     7.066\n",
       "Date:                Tue, 05 Dec 2017   Prob (F-statistic):           1.25e-39\n",
       "Time:                        10:54:47   Log-Likelihood:                -3016.0\n",
       "No. Observations:                1257   AIC:                             6132.\n",
       "Df Residuals:                    1207   BIC:                             6389.\n",
       "Df Model:                          49                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "const                              15.2241      0.950     16.027      0.000      13.361      17.088\n",
       "instrumentalness_mean              -3.1447      1.089     -2.887      0.004      -5.282      -1.008\n",
       "liveness_mean                     -12.1780      2.358     -5.164      0.000     -16.804      -7.552\n",
       "loudness_std                        3.3418      1.299      2.572      0.010       0.793       5.891\n",
       "speech_mean                        -2.5326      0.971     -2.608      0.009      -4.438      -0.627\n",
       "time_std                         -1.25e-08   3.99e-09     -3.131      0.002   -2.03e-08   -4.67e-09\n",
       "valence_mean                       -7.3241      1.413     -5.183      0.000     -10.096      -4.552\n",
       " 'bass music'                      -0.4514      0.405     -1.116      0.265      -1.245       0.342\n",
       " 'big band'                         0.2267      0.316      0.718      0.473      -0.393       0.847\n",
       " 'christian punk'                  -1.1516      0.685     -1.682      0.093      -2.495       0.192\n",
       " 'country gospel'                  -0.1673      0.326     -0.514      0.607      -0.806       0.471\n",
       " 'crunk'                            1.4932      0.785      1.901      0.058      -0.048       3.034\n",
       " 'deep house'                       0.3671      0.299      1.226      0.220      -0.220       0.954\n",
       " 'dubstep'                          0.6460      0.540      1.196      0.232      -0.414       1.706\n",
       " 'ectofolk'                        -2.1576      1.148     -1.880      0.060      -4.409       0.094\n",
       " 'electro house'                   -0.2006      0.233     -0.859      0.390      -0.659       0.257\n",
       " 'escape room'                      0.6030      0.182      3.308      0.001       0.245       0.961\n",
       " 'experimental'                     0.1237      0.213      0.580      0.562      -0.295       0.543\n",
       " 'filter house'                     1.0122      0.338      2.993      0.003       0.349       1.676\n",
       " 'garage rock'                      0.2319      0.201      1.154      0.249      -0.163       0.626\n",
       " 'latin pop'                        0.4265      0.220      1.942      0.052      -0.004       0.857\n",
       " 'modern blues'                     0.5259      0.187      2.809      0.005       0.159       0.893\n",
       " 'modern country rock'              0.4418      0.190      2.321      0.020       0.068       0.815\n",
       " 'new orleans jazz'                -0.4096      0.363     -1.128      0.260      -1.122       0.303\n",
       " 'pop emo'                         -0.1501      0.209     -0.719      0.472      -0.560       0.259\n",
       " 'pop punk'                         0.4633      0.185      2.504      0.012       0.100       0.826\n",
       " 'progressive electro house'        0.5527      0.332      1.666      0.096      -0.098       1.203\n",
       " 'progressive house'               -0.3463      0.331     -1.048      0.295      -0.995       0.302\n",
       " 'progressive uplifting trance'    -0.3538      0.817     -0.433      0.665      -1.957       1.250\n",
       " 'traditional folk'                -0.0593      0.365     -0.163      0.871      -0.776       0.657\n",
       " 'trip hop'                         0.9485      0.391      2.429      0.015       0.182       1.715\n",
       "'alternative rock'                  0.1924      0.197      0.974      0.330      -0.195       0.580\n",
       "'austindie'                         0.6574      0.505      1.301      0.194      -0.334       1.649\n",
       "'blues-rock'                       -0.3016      0.243     -1.241      0.215      -0.778       0.175\n",
       "'canadian metal'                    0.7083      0.857      0.827      0.409      -0.972       2.389\n",
       "'chillhop'                         -0.6586      0.847     -0.778      0.437      -2.320       1.003\n",
       "'columbus ohio indie'              -0.8179      0.535     -1.528      0.127      -1.868       0.233\n",
       "'dance-punk'                       -0.3826      0.571     -0.670      0.503      -1.503       0.738\n",
       "'deep new americana'                0.0373      0.218      0.171      0.864      -0.391       0.465\n",
       "'edm'                               0.6196      0.301      2.062      0.039       0.030       1.209\n",
       "'g funk'                           -0.5112      0.420     -1.217      0.224      -1.335       0.313\n",
       "'indie punk'                        0.0738      0.430      0.172      0.864      -0.769       0.917\n",
       "'pop'                               0.5996      0.276      2.175      0.030       0.059       1.140\n",
       "'progressive post-hardcore'         0.7197      0.449      1.603      0.109      -0.161       1.600\n",
       "'speed garage'                     -0.3341      0.646     -0.517      0.605      -1.602       0.933\n",
       "Radiohead                          -0.8771      0.821     -1.068      0.286      -2.489       0.735\n",
       "Str_Best                           -1.2647      0.330     -3.837      0.000      -1.911      -0.618\n",
       "Str_Acoustic                        3.1248      0.617      5.064      0.000       1.914       4.335\n",
       "Str_2000s                          -3.0511      0.381     -8.006      0.000      -3.799      -2.303\n",
       "dance_liveness_std                 -0.1096      0.030     -3.650      0.000      -0.169      -0.051\n",
       "==============================================================================\n",
       "Omnibus:                       31.737   Durbin-Watson:                   1.975\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               33.675\n",
       "Skew:                          -0.395   Prob(JB):                     4.87e-08\n",
       "Kurtosis:                       2.868   Cond. No.                     6.39e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.39e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit a multilinear regression model with significant predictors\n",
    "x_train2 = x_train[sig_preds]\n",
    "x_test2 = x_test[sig_preds]\n",
    "\n",
    "X7=sm.add_constant(x_train2)\n",
    "X8=sm.add_constant(x_test2)\n",
    "model5=sm.OLS(y_train,X7)\n",
    "results5=model5.fit()\n",
    "r2_test_e=r2_score(y_test,results5.predict(X8))\n",
    "print(\"With only the significant terms from the last model,R2 score for test set: {}\".format(r2_test_e))\n",
    "results5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (f) Bootstrapping for 10% Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part (e), we observe that a smaller subset of original predictors may do a lot better in terms of test set prediction. Therefore, in part (f), we randomly choose 10% of predictors and fit a regression model. We do 500 iterations and record corresponding r2 test core and the associated predictors.\n",
    "\n",
    "We achieve a r2 test score of 0.21. However,since we are just randomly choosing predictors, this result could come from chance alone and may not be very robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##bootstrapping for10% predictors\n",
    "r2_test=[]\n",
    "pred=[]\n",
    "for i in range(500):\n",
    "    train_col=[]\n",
    "    while len(train_col)==0:\n",
    "        for ele in x_train.columns:\n",
    "            u=np.random.uniform(0,1)\n",
    "            if u>0.9:\n",
    "                if ele!='Followers':\n",
    "                    train_col.append(ele)\n",
    "    pred.append(train_col)\n",
    "    x_train1 = x_train[train_col]\n",
    "    x_test1 = x_test[train_col]\n",
    "    multi2 =LinearRegression(fit_intercept=True)# no need to add constant when doing it this way\n",
    "    multi2.fit(x_train1, y_train)\n",
    "\n",
    "    r2_test.append(multi2.score(x_test1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findLargest(r2):\n",
    "    largest=r2[0]\n",
    "    count=0\n",
    "    for i in range(len(r2)):\n",
    "        if r2[i]>largest:\n",
    "            largest=r2[i]\n",
    "            count=i\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After bootstrapping for 10% of predictors, the best R2 score for test set: 0.21855216986291626\n",
      "The assocaited predictors are\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['acousticness_mean',\n",
       " 'liveness_std',\n",
       " 'loudness_mean',\n",
       " 'valence_mean',\n",
       " 'followers_std',\n",
       " 'top_0_10',\n",
       " \" 'ambient'\",\n",
       " \" 'bebop'\",\n",
       " \" 'bluegrass'\",\n",
       " \" 'bow pop'\",\n",
       " \" 'chillhop'\",\n",
       " \" 'classic rock'\",\n",
       " \" 'classical piano'\",\n",
       " \" 'contemporary jazz'\",\n",
       " \" 'country dawn'\",\n",
       " \" 'deep talent show'\",\n",
       " \" 'desi hip hop'\",\n",
       " \" 'ethereal wave'\",\n",
       " \" 'freestyle'\",\n",
       " \" 'future garage'\",\n",
       " \" 'garage punk blues'\",\n",
       " \" 'heavy alternative'\",\n",
       " \" 'indie dream pop'\",\n",
       " \" 'indie garage rock'\",\n",
       " \" 'indie psych-rock'\",\n",
       " \" 'intelligent dance music'\",\n",
       " \" 'latin metal'\",\n",
       " \" 'metropopolis'\",\n",
       " \" 'modern uplift'\",\n",
       " \" 'motown'\",\n",
       " \" 'nashville sound'\",\n",
       " \" 'neo-industrial rock'\",\n",
       " \" 'new americana'\",\n",
       " \" 'noise rock'\",\n",
       " \" 'nu gaze'\",\n",
       " \" 'ok indie'\",\n",
       " \" 'piano blues'\",\n",
       " \" 'pop christmas'\",\n",
       " \" 'pop'\",\n",
       " \" 'power metal'\",\n",
       " \" 'progressive house'\",\n",
       " \" 'progressive post-hardcore'\",\n",
       " \" 'retro electro'\",\n",
       " \" 'scorecore'\",\n",
       " \" 'sludge metal'\",\n",
       " \" 'southern soul'\",\n",
       " \" 'swedish indie rock'\",\n",
       " \" 'teen pop'\",\n",
       " \" 'trance'\",\n",
       " \" 'triangle indie'\",\n",
       " \" 'tropical house'\",\n",
       " \" 'uk post-punk'\",\n",
       " \" 'vocal house'\",\n",
       " '\"children\\'s christmas\"',\n",
       " \"'alternative rock'\",\n",
       " \"'australian alternative rock'\",\n",
       " \"'baroque'\",\n",
       " \"'blackgaze'\",\n",
       " \"'canadian country'\",\n",
       " \"'canadian pop'\",\n",
       " \"'cantautor'\",\n",
       " \"'chillhop'\",\n",
       " \"'deep contemporary country'\",\n",
       " \"'desert blues'\",\n",
       " \"'djent'\",\n",
       " \"'dreamo'\",\n",
       " \"'drone'\",\n",
       " \"'east coast hip hop'\",\n",
       " \"'house'\",\n",
       " \"'indie pop'\",\n",
       " \"'indie poptimism'\",\n",
       " \"'indie psych-rock'\",\n",
       " \"'mellow gold'\",\n",
       " \"'minimal techno'\",\n",
       " \"'ninja'\",\n",
       " \"'skate punk'\",\n",
       " \"'vancouver indie'\",\n",
       " \"'wrestling'\",\n",
       " 'Rihanna',\n",
       " 'Chance The Rapper',\n",
       " 'Otis Redding',\n",
       " 'SZA',\n",
       " 'Birdy',\n",
       " 'Commodores',\n",
       " 'Str_Party',\n",
       " 'Str_Acoustic',\n",
       " 'Str_2000s',\n",
       " 'acoustic_key_std']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"After bootstrapping for 10% of predictors, the best R2 score for test set: {}\".format(r2_test[findLargest(r2_test)]))\n",
    "len(pred[findLargest(r2_test)])\n",
    "print('The assocaited predictors are')\n",
    "pred[findLargest(r2_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part(g) PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to cut down the number of predictors, we implement PCA here. We choose number of PCA components from 1 to 100 and choose the optimal number of PCA components.\n",
    "\n",
    "We acheive the best r2 test score of 0.13 with 30 PCA components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13027619329603601"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "r2_test_pca=[]\n",
    "for i in range(1,100):\n",
    "    pca = PCA(n_components=i)\n",
    "    pca.fit(x_train)\n",
    "    x_train_pca = pca.transform(x_train)\n",
    "    x_test_pca = pca.transform(x_test)\n",
    "    pca_regression_model = LinearRegression(fit_intercept=True)\n",
    "    pca_regression_model.fit(x_train_pca, y_train)\n",
    "    r2_test_pca.append(pca_regression_model.score(x_test_pca, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After PCA, the best R2 score for test set: 0.130276193296036\n",
      "The optimal number of components is: 30\n"
     ]
    }
   ],
   "source": [
    "print(\"After PCA, the best R2 score for test set: {}\".format(r2_test_pca[findLargest(r2_test_pca)]))\n",
    "print(\"The optimal number of components is: {}\".format(findLargest(r2_test_pca)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part(h) Lasso and Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part (h), we fit Ridge and Lasso with cross validation and with lamda ranging from 1e^-5 to 10^5.\n",
    "\n",
    "With Lasso, the test r2 score is 0.109.\n",
    "\n",
    "With Ridge, the test r2 score is 0.112."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With lasso, R2 score for test set: 0.1094129599174094\n"
     ]
    }
   ],
   "source": [
    "#lasso CV\n",
    "lambda_list=[pow(10,i) for i in range(-5,5)]\n",
    "lasso_regression = LassoCV(alphas=lambda_list, fit_intercept=True)\n",
    "lasso_regression.fit(x_train, y_train)\n",
    "print(\"With lasso, R2 score for test set: {}\".format(lasso_regression.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With ridge, R2 score for test set: 0.11234514421712671\n"
     ]
    }
   ],
   "source": [
    "#ridge\n",
    "ridge_regression = RidgeCV(cv=10,alphas=lambda_list, fit_intercept=True, normalize=True)\n",
    "ridge_regression.fit(x_train, y_train)\n",
    "print(\"With ridge, R2 score for test set: {}\".format(ridge_regression.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 949 predictors in our original data, we encounter the problem of overfitting when constructing regression models. Therefore, for basline models, we focus on selecting a subgroup of predictors that perform well in terms of r2 test score. By using only the significant predictors from the full model, test r2 score improves a lot (from -2.7 to 0.8). PCA gives us r2 score of 0.13. Lasso gives up 0.109 and Ridge gives us 0.11. We should note that iteratively choosing 10% of predictors gives us the best baseline r2 metric (0.21). However, this model is not robust and tend toward overfitting since we do not methodologically choose the predictors. Still, we could use 0.21 as a reference when evaluating our future models. In summary, the most robust and predictive baseline model is PCA with r2 socre of 0.13. But we may use 0.21 as baseline r2_test metric for the furture. In addition, we should consider including top 30 artists predictors since they alone gives us 0.03 r2 test metric. On the other hand, we should carefully select which genre predictors to include since there are 865 of them and would lead to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
